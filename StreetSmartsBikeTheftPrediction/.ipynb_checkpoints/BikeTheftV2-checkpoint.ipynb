{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scipy) (1.15.4)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (0.23.4)\n",
      "Requirement already satisfied: patsy in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas->statsmodels) (2.7.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas->statsmodels) (1.15.4)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas->statsmodels) (2018.7)\n",
      "Requirement already satisfied: six in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from patsy->statsmodels) (1.11.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from seaborn) (1.15.4)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2018.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (39.0.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from sklearn) (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scikit-learn->sklearn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: gmplot in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmplot) (2.20.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests->gmplot) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests->gmplot) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests->gmplot) (2018.10.15)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests->gmplot) (2.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.15.4)\n",
      "Requirement already satisfied: gmaps in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.8.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmaps) (7.1.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmaps) (7.4.2)\n",
      "Requirement already satisfied: traitlets>=4.3.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmaps) (4.3.2)\n",
      "Requirement already satisfied: geojson>=2.0.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmaps) (2.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from gmaps) (1.11.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (2.0.7)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (39.0.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (0.1.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (2.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (0.13.1)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipython>=5.3.0->gmaps) (0.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipywidgets>=7.0.0->gmaps) (5.1.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipywidgets>=7.0.0->gmaps) (4.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipywidgets>=7.0.0->gmaps) (3.4.2)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from traitlets>=4.3.0->gmaps) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.3.0->gmaps) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from jedi>=0.10->ipython>=5.3.0->gmaps) (0.3.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (5.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->gmaps) (2.6.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->gmaps) (4.4.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (5.7.0)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (17.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (2.7.5)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.8.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (5.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (2.10)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.4.2)\n",
      "Requirement already satisfied: pywinpty>=0.5; os_name == \"nt\" in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.5.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.4.2)\n",
      "Requirement already satisfied: mistune>=0.8.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.2.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (1.4.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (3.0.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (1.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=7.0.0->gmaps) (0.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\users\\irfan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from geopy) (1.49)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install statsmodels\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n",
    "!pip install gmplot\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install gmaps\n",
    "!pip install geopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sf\n",
    "import gmplot\n",
    "import gmaps\n",
    "import geopy.distance\n",
    "import math\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Settings\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline\n",
    "\n",
    "gmaps.configure(api_key='AIzaSyBCqDDDf9HpgSmohNjatDRTgmYqYUuqv_c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {'Lat':0,\n",
    "        'Long':1,\n",
    "        'Incidents':2,\n",
    "        'PoliceStations':3,\n",
    "        'BikeLockers':4,\n",
    "        'LCBO':5,\n",
    "        'SubwayStations':6,\n",
    "        'PawnShops':7,\n",
    "        'BikeStores':8\n",
    "}\n",
    "\n",
    "poi_data = [\n",
    "    {\n",
    "        \"prefix\": \"police_stations\",\n",
    "        \"fileName\": \"Coordinates_Police_Stations.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"bike_lockers\",\n",
    "        \"fileName\": \"Coordinates_Bike_Lockers.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"lcbo\",\n",
    "        \"fileName\": \"Coordinates_LCBO.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"subway_stations\",\n",
    "        \"fileName\": \"Coordinates_Subway_Stations.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\":\"pawn_shops\",\n",
    "        \"fileName\": \"Coordinates_Pawn_Shops.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"bike_stores\",\n",
    "        \"fileName\": \"Coordinates_Bike_Stores.csv\"\n",
    "    },\n",
    "]\n",
    "\n",
    "pois = ['closest_police_stations_distance',\n",
    "        'closest_bike_lockers_distance',\n",
    "        'closest_lcbo_distance',\n",
    "        'closest_subway_stations_distance',\n",
    "        'closest_pawn_shops_distance',\n",
    "        'closest_bike_stores_distance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin Thefts into Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateGrid(info, square_size):\n",
    "\n",
    "    # ================\n",
    "    # Read Data\n",
    "    # ================\n",
    "    thefts = pd.read_csv('Bicycle_Thefts.csv')\n",
    "    locations_df = thefts[['Lat', 'Long']].copy()\n",
    "\n",
    "    # ===========================\n",
    "    # Calculate Grid Dimensions\n",
    "    # ===========================\n",
    "    min_lat = min(thefts['Lat'])\n",
    "    max_lat = max(thefts['Lat'])\n",
    "    min_lon = min(thefts['Long'])\n",
    "    max_lon = max(thefts['Long'])\n",
    "\n",
    "    lat_range = geopy.distance.vincenty((min_lat, min_lon), (max_lat, min_lon)).m\n",
    "    lon_range = geopy.distance.vincenty((min_lat, min_lon), (min_lat, max_lon)).m\n",
    "\n",
    "    num_y_grids = round (lat_range / square_size)\n",
    "    num_x_grids = round (lon_range / square_size)\n",
    "\n",
    "    grid_y_dim = abs(max_lat - min_lat) / num_y_grids\n",
    "    grid_x_dim = abs(max_lon - min_lon) / num_x_grids\n",
    "\n",
    "    # =====================================\n",
    "    # Create a Grid\n",
    "    # =====================================\n",
    "    grid_thefts = np.zeros((num_y_grids * num_x_grids, 3))\n",
    "\n",
    "    # ===================================\n",
    "    # Populate the Grid Coordinates\n",
    "    # ===================================\n",
    "    print (\"\\nPopulating the Grid Coordinates\\n\")\n",
    "    for y in range (0, num_y_grids):   \n",
    "        for x in range (0, num_x_grids):\n",
    "            grid_thefts[y * num_x_grids + x, info['Lat']] = min_lat + (y + 0.5) * grid_y_dim\n",
    "            grid_thefts[y * num_x_grids + x, info['Long']] = min_lon + (x + 0.5) * grid_x_dim\n",
    "\n",
    "    # ===================================\n",
    "    # Populate the Grid with Incidents\n",
    "    # ===================================\n",
    "    print(\"Populating the Grid with Thefts\\n\")\n",
    "    for theft in range(0, len(thefts)):\n",
    "        theft_lat = thefts['Lat'][theft]\n",
    "        theft_lon = thefts['Long'][theft]\n",
    "        ratio_y = abs(theft_lat - min_lat) / abs(max_lat - min_lat)\n",
    "        ratio_x = abs(theft_lon - min_lon) / abs(max_lon - min_lon)\n",
    "        grid_y = int(round( ratio_y * num_y_grids)) - 1\n",
    "        grid_x = int(round( ratio_x * num_x_grids)) - 1\n",
    "        grid_thefts [grid_y * num_x_grids + grid_x, info['Incidents']] += 1\n",
    "\n",
    "    # ===================================\n",
    "    # Create the Final Grid\n",
    "    # ===================================\n",
    "    print(\"Creating the Final Grid\\n\")\n",
    "    grid_final = pd.DataFrame(grid_thefts)\n",
    "    grid_final.columns = ['Lat',\n",
    "                          'Long',\n",
    "                          'Incidents']\n",
    "    \n",
    "    \n",
    "    return grid_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindClosest(bike_thefts_df, points_of_interest_df, col_prefix):\n",
    "    closest_pois = []\n",
    "            \n",
    "    for theft_index, theft_row in bike_thefts_df.iterrows():\n",
    "        closest_poi = (0,0, float('inf'))\n",
    "        theft_loc = (theft_row['Lat'], theft_row['Long'])\n",
    "        if math.isnan(theft_loc[0]) or math.isnan(theft_loc[1]):\n",
    "            continue\n",
    "        for poi_index, poi_row in points_of_interest_df.iterrows():\n",
    "            poi_loc = (poi_row['Latitude'], poi_row['Longitude'])\n",
    "            if math.isnan(poi_loc[0]) or math.isnan(poi_loc[1]):\n",
    "                continue\n",
    "            distance = geopy.distance.vincenty(theft_loc, poi_loc).m\n",
    "            if distance < closest_poi[2]:\n",
    "                closest_poi = (poi_loc[0], poi_loc[1], distance)\n",
    "                \n",
    "        closest_pois.append(closest_poi)\n",
    "    \n",
    "    bike_thefts_df['closest_' + col_prefix + '_distance'] = list(map(lambda x: x[2], closest_pois))\n",
    "    return bike_thefts_df['closest_' + col_prefix + '_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddNearestPointsOfInterest(grid, poi_data, folder, filename):\n",
    "    # =========================================\n",
    "    # Calculate the Nearest Points of Interest\n",
    "    # =========================================\n",
    "    print (\"Populating Nearest Points of Interest\\n\")\n",
    "    poi_dfs = {}\n",
    "    for entry in poi_data:\n",
    "        print('Populating ' + entry['prefix'] + \"...\")\n",
    "        poi_df = pd.read_csv(\"./\" + folder + \"/\" + entry['fileName'])\n",
    "        FindClosest(grid, poi_df, entry['prefix'])\n",
    "        grid.to_csv('./' + filename + '.csv')\n",
    "\n",
    "    grid.to_csv('./' + filename + '.csv')\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridBinner(info, poi_data, folder, filename, square_size):\n",
    "    \n",
    "    grid = CreateGrid(info, square_size)\n",
    "    grid = grid[grid.Incidents!=0] #Drop Zero Grids that add noise\n",
    "    grid = AddNearestPointsOfInterest(grid, poi_data, folder, filename)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Populating the Grid Coordinates\n",
      "\n",
      "Populating the Grid with Thefts\n",
      "\n",
      "Creating the Final Grid\n",
      "\n",
      "Populating Nearest Points of Interest\n",
      "\n",
      "Populating police_stations...\n",
      "Populating bike_lockers...\n",
      "Populating lcbo...\n",
      "Populating subway_stations...\n"
     ]
    }
   ],
   "source": [
    "grid200 = GridBinner(info, poi_data, folder= \"originalPOI\", filename=\"200m_nonzero_grid\", square_size=200)\n",
    "grid100 = GridBinner(info, poi_data, folder= \"originalPOI\", filename=\"100m_nonzero_grid\", square_size=100)\n",
    "grid50 = GridBinner(info, poi_data, folder= \"originalPOI\", filename=\"50m_nonzero_grid\", square_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Closest Point of Interest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('200m_nonzero_grid.csv')\n",
    "#data = pd.read_csv('100m_nonzero_grid.csv')\n",
    "#data = pd.read_csv('50m_nonzero_grid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotNearestPOI(data, pois):\n",
    "    \n",
    "    for poi in pois:\n",
    "        data.plot(kind='scatter', x=\"%s\" %(poi), y='Incidents', figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotNearestPOI(data, pois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct (y, X) dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetYX(data, pois):\n",
    "    \n",
    "    y = data['Incidents']\n",
    "    X = data[pois]\n",
    "        \n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = GetYX(data, pois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLinearModel(X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split (\n",
    "        X,\n",
    "        y,\n",
    "        train_size = 0.70,\n",
    "        test_size = 0.30,\n",
    "    )\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    linear_model = linear_model.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    train_results = linear_model.predict(X_train)\n",
    "    test_results = linear_model.predict(X_test)\n",
    "      \n",
    "    trainScore = linear_model.score(X_train, y_train)\n",
    "    testScore = linear_model.score(X_test, y_test)\n",
    "    \n",
    "    print (\"TRAIN %f TEST %f\" %(trainScore, testScore))\n",
    "    \n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = CreateLinearModel(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the data into three categories of bike theft prevalence\n",
    "def mapRiskGroup(y):\n",
    "    y_remapped = [1 if i < 5 else 2 if i < 10 else 3 for i in y] \n",
    "    #y_remapped = [1 if i < 4 else 2 if i < 10 else 3 for i in y] \n",
    "    #y_remapped = [1 if i < 5 else 2 if i < 8 else 3 if i < 15 else 4 for i in y] \n",
    "    return y_remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mapRiskGroup(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMultiLogisticModel(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split (\n",
    "        X,\n",
    "        y,\n",
    "        train_size = 0.70,\n",
    "        test_size = 0.30,\n",
    "    )\n",
    "    \n",
    "    multi_logistic_model = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    multi_logistic_model = multi_logistic_model.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    train_results = multi_logistic_model.predict(X_train)\n",
    "    test_results = multi_logistic_model.predict(X_test)\n",
    "      \n",
    "    trainScore = accuracy_score(y_train, train_results)\n",
    "    testScore = accuracy_score(y_test, test_results)\n",
    "\n",
    "    print (\"TRAINING CONFUSION MATRIX\")\n",
    "    cm = confusion_matrix(y_train, train_results)\n",
    "    sns.heatmap(cm, center=True,annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print (\"TESTING CONFUSION MATRIX\")\n",
    "    cm = confusion_matrix(y_test, test_results)\n",
    "    sns.heatmap(cm, center=True,annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print (\"TRAIN %f TEST %f\" %(trainScore, testScore))\n",
    "    \n",
    "    return multi_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logistic_model = CreateMultiLogisticModel(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetModel:\n",
    "    def __init__(self, x_train, y_train, hidden_layer_sizes=(50,50,50), max_iter=5000, alpha=0.0001, solver='sgd', verbose=False,  random_state=21,tol=0.000000001):\n",
    "        self.scaler = StandardScaler() #scale data to allow for easier neural net inference and error improvement\n",
    "        self.scaler.fit(x_train)\n",
    "\n",
    "        _x_train = self.scaler.transform(x_train)\n",
    "        self.clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, alpha=alpha, solver=solver, verbose=verbose,  random_state=random_state,tol=tol)\n",
    "        self.clf.fit(_x_train, y_train)\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        _x_test = self.scaler.transform(x_test)\n",
    "        y_pred = self.clf.predict(_x_test) #Predict\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateNeuralNetModel(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split (\n",
    "        X,\n",
    "        y,\n",
    "        train_size = 0.70,\n",
    "        test_size = 0.30,\n",
    "    )\n",
    "    \n",
    "    nn_model = NeuralNetModel(X_train, y_train, verbose=False)\n",
    "    \n",
    "    y_train_prediction = nn_model.predict(X_train)\n",
    "    y_test_prediction = nn_model.predict(X_test)\n",
    "      \n",
    "    trainScore = accuracy_score(y_train, y_train_prediction)\n",
    "    testScore = accuracy_score(y_test, y_test_prediction)\n",
    "    \n",
    "    print (\"TRAINING CONFUSION MATRIX\")\n",
    "    cm = confusion_matrix(y_train, y_train_prediction)\n",
    "    sns.heatmap(cm, center=True,annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print (\"TESTING CONFUSION MATRIX\")\n",
    "    cm = confusion_matrix(y_test, y_test_prediction)\n",
    "    sns.heatmap(cm, center=True,annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print (\"TRAIN %f TEST %f\" %(trainScore, testScore))\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = CreateNeuralNetModel(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with New Points of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = pd.read_csv('200m_nonzero_updated_pois_grid.csv')\n",
    "\n",
    "y_updated, X_updated = GetYX(updated_data, pois)\n",
    "y_updated = mapRiskGroup(y_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Incident Rate with Subway Relief Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(model, X):\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_grid_prediction = Predict(nn_model, X)\n",
    "updated_grid_prediction = Predict(nn_model, X_updated)\n",
    "delta_grid_prediction = abs(original_grid_prediction - updated_grid_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_grid_prediction.tolist()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Updated Subway Line Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_csv = data[['Lat','Long']]\n",
    "original_csv['Incidents'] = original_grid_prediction\n",
    "original_csv.to_csv(\"OriginalOut.csv\")\n",
    "\n",
    "updated_csv = updated_data[['Lat','Long']]\n",
    "updated_csv['Incidents'] = updated_grid_prediction\n",
    "updated_csv.to_csv(\"UpdatedOut.csv\")\n",
    "\n",
    "delta_csv = data[['Lat','Long']]\n",
    "delta_csv['Incidents'] = delta_grid_prediction\n",
    "delta_csv.to_csv(\"DeltaOut.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateHeatMap(file, max_intensity=3, point_radius=8):\n",
    "    data = pd.read_csv(file)\n",
    "    data = data[data.Incidents != 0]\n",
    "    points = data[['Lat', 'Long']]\n",
    "    incidents = data['Incidents']\n",
    "    TO_coords = (43.65, -79.395)\n",
    "    heatmap = gmaps.figure(center=TO_coords, zoom_level=11.7)\n",
    "\n",
    "    layer = gmaps.heatmap_layer(points, weights=incidents, max_intensity=max_intensity, point_radius=point_radius)\n",
    "    \n",
    "    layer.gradient = [\n",
    "        (200, 200, 200, 0), # transparent\n",
    "        (255, 246, 5), # yellow\n",
    "        (255, 109, 5), # orange\n",
    "        (193, 3  , 3), # red\n",
    "    ]\n",
    "    heatmap.add_layer(layer)\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateHeatMap(file = '200m_nonzero_grid.csv', max_intensity=10, point_radius=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateHeatMap(file = 'OriginalOut.csv', max_intensity=3, point_radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateHeatMap(file = 'UpdatedOut.csv', max_intensity=3, point_radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateHeatMap(file = 'DeltaOut.csv', max_intensity=2, point_radius=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
